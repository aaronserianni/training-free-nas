{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train models for BERT ablation study, on Google Collab with TPUs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBzj8saQAK9s",
        "outputId": "0302fdc5-1c2a-45e3-ccc6-c75230b83246"
      },
      "outputs": [],
      "source": [
        "# Enter Google Collab storage bucket information here\n",
        "project_id = \"\"\n",
        "bucket_name = \"\"\n",
        "from google.colab import auth\n",
        "\n",
        "auth.authenticate_user()\n",
        "\n",
        "!gcloud config set project {project_id}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkSJpFcevKNs",
        "outputId": "8ae714a4-cdbc-4553-87e7-c033161c27a1"
      },
      "outputs": [],
      "source": [
        "!pip install -U numpy==1.19.5\n",
        "!pip install tensorflow-gpu==1.15\n",
        "\n",
        "import csv\n",
        "import json\n",
        "import os\n",
        "import time\n",
        "\n",
        "import regex as re\n",
        "from google.cloud import storage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46QA5pfOe5-k",
        "outputId": "5c9f51a1-58ad-4edc-b6db-73afe2e4d3f3"
      },
      "outputs": [],
      "source": [
        "!gsutil -m cp -nr gs://{bucket_name}/electra-nas ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0fcW3r3v1o-"
      },
      "outputs": [],
      "source": [
        "def download_configs():\n",
        "    client = storage.Client()\n",
        "    bucket = client.bucket(bucket_name)\n",
        "    blob = bucket.blob(\"BERT_benchmark_train_ablation.json\")\n",
        "    return json.loads(blob.download_as_string())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "timDSZkhv1o_"
      },
      "outputs": [],
      "source": [
        "def get_config():\n",
        "    configs = download_configs()\n",
        "    config = {}\n",
        "    for tempconfig in configs:\n",
        "        if not tempconfig[\"is_running\"] and not tempconfig[\"completed\"]:\n",
        "            config = tempconfig\n",
        "            break\n",
        "\n",
        "    hparams = config[\"hparams\"]\n",
        "    hparams[\"tpu_name\"] += os.environ[\"COLAB_TPU_ADDR\"]\n",
        "\n",
        "    with open(\"hparams.json\", \"w\") as f:\n",
        "        json.dump(hparams, f, indent=4)\n",
        "    \n",
        "    return config[\"id\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "izZ5QQuMv1o_"
      },
      "outputs": [],
      "source": [
        "def run_pretraining(config_id):\n",
        "    model_name = \"ablation\" + str(config_id)\n",
        "    \n",
        "    client = storage.Client()\n",
        "    bucket = client.bucket(bucket_name)\n",
        "\n",
        "    configs = download_configs()\n",
        "    config = configs[config_id]\n",
        "\n",
        "    !gsutil -m rm -r gs://{bucket_name}/electra_data/models/{model_name}\n",
        "    \n",
        "    start_time = time.time()\n",
        "    config[\"is_running\"] = True\n",
        "\n",
        "    configs[config[\"id\"]] = config\n",
        "    blob = bucket.blob(\"BERT_benchmark_train_ablation.json\")\n",
        "    blob.upload_from_string(json.dumps(configs).encode('utf-8'))\n",
        "\n",
        "    !python tensorflow-model/run_pretraining.py --data-dir gs://{bucket_name}/electra_data/ --model-name {model_name} --hparams hparams.json\n",
        "    end_time = time.time()\n",
        "\n",
        "    configs = download_configs()\n",
        "    config = configs[config_id]\n",
        "    config[\"time_to_train\"] = end_time - start_time\n",
        "    config[\"is_running\"] = False\n",
        "    config[\"completed\"] = True\n",
        "\n",
        "    configs[config[\"id\"]] = config\n",
        "    blob = bucket.blob(\"BERT_benchmark_train_ablation.json\")\n",
        "    blob.upload_from_string(json.dumps(configs).encode('utf-8'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5aZ95Rltv1o_"
      },
      "outputs": [],
      "source": [
        "def run_finetuning(config_id):\n",
        "    model_name = \"ablation\" + str(config_id)\n",
        "\n",
        "    !gsutil -m cp -nr gs://{bucket_name}/electra_data/finetuning_tfrecords gs://{bucket_name}/electra_data/models/{model_name}/\n",
        "\n",
        "    with open(\"hparams.json\", \"r\") as f:\n",
        "        hparams_finetuning = json.load(f)\n",
        "\n",
        "    hparams_finetuning[\"eval_batch_size\"] = 32\n",
        "    hparams_finetuning[\"train_batch_size\"] = 32\n",
        "    num_train_steps = hparams_finetuning.pop(\"num_train_steps\")\n",
        "    hparams_finetuning.pop(\"keep_checkpoint_max\")\n",
        "\n",
        "    glue_tasks = [\"cola\", \"mnli\", \"mrpc\", \"qnli\", \"qqp\", \"rte\", \"sst\", \"sts\"]\n",
        "    \n",
        "    for i in range(0, num_train_steps+1, hparams_finetuning['save_checkpoints_steps']):\n",
        "        hparams_finetuning[\"init_checkpoint\"] = \"gs://{bucket_name}/electra_data/models/\" + model_name + \"/model.ckpt-\" + str(i)\n",
        "\n",
        "        for task in glue_tasks:\n",
        "            hparams_finetuning[\"task_names\"] = [task]\n",
        "            hparams_finetuning[\"results_txt\"] = (\n",
        "                \"gs://\" + bucket_name + \"/electra_data/models/\"\n",
        "                + model_name\n",
        "                + \"/results/model.\"\n",
        "                + str(i)\n",
        "                + \".\"\n",
        "                + task\n",
        "                + \"_results.txt\"\n",
        "            )\n",
        "            with open(\"hparams_finetuning.json\", \"w\") as f:\n",
        "                json.dump(hparams_finetuning, f, indent=4)\n",
        "\n",
        "            !python3 tensorflow-model/run_finetuning.py --data-dir gs://{bucket_name}/electra_data/ --model-name {model_name} --hparams hparams_finetuning.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "10FBbIvhv1pA"
      },
      "outputs": [],
      "source": [
        "def save_results(config_id):\n",
        "    model_name = \"ablation\" + str(config_id)\n",
        "\n",
        "    client = storage.Client()\n",
        "    bucket = client.bucket(bucket_name)\n",
        "\n",
        "    glue_tasks = [\"cola\", \"mnli\", \"mrpc\", \"qnli\", \"qqp\", \"rte\", \"sst\", \"sts\"]\n",
        "\n",
        "    configs = download_configs()\n",
        "    config = configs[config_id]\n",
        "\n",
        "    for i in range(0, config['hparams']['num_train_steps']+1, config['hparams']['save_checkpoints_steps']):\n",
        "        glue_score = 0\n",
        "        config[\"scores\"][str(i)] = {}\n",
        "        for blob in bucket.list_blobs(\n",
        "            prefix=\"electra_data/models/\" + model_name + \"/results/model.\" + str(i)\n",
        "        ):\n",
        "            contents = blob.download_as_string()\n",
        "            task = next(task for task in glue_tasks if task in blob.name)\n",
        "            if task is not None:\n",
        "                config[\"scores\"][str(i)][task] = float(re.search(\"(?<= [a-z]+: ).*?(?= )\", str(contents)).group())\n",
        "                glue_score += config[\"scores\"][str(i)][task]\n",
        "\n",
        "        config[\"scores\"][str(i)][\"glue\"] = glue_score/len(glue_tasks)\n",
        "        configs[config[\"id\"]] = config\n",
        "        blob = bucket.blob(\"BERT_benchmark_train_ablation.json\")\n",
        "        blob.upload_from_string(json.dumps(configs).encode('utf-8'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "0t-AUIF5v1pB",
        "outputId": "584d2eeb-af75-4fbd-dc30-0c21391d0e87"
      },
      "outputs": [],
      "source": [
        "while(True):\n",
        "    config_id = get_config()\n",
        "    run_pretraining(config_id)\n",
        "    run_finetuning(config_id)\n",
        "    save_results(config_id)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "name": "nas-ablation1",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.13 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
